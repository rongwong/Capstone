{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "\n",
    "# import cv2\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import os, os.path\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# from skimage.feature import Cascade\n",
    "# import skimage \n",
    "# from skimage import data, color\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from autocrop import Cropper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_to_train(loop_list, end_directory):\n",
    "    \"\"\"moves images from folders into another folder\"\"\"\n",
    "    for paths in loop_list:\n",
    "        for image in paths:\n",
    "            copyfile(image, end_directory)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fer_to_combined(loop_list, end_directory):\n",
    "    \"\"\"moves images from fer2013 folders into combined folder\"\"\"\n",
    "    img_num = 0\n",
    "    for paths in loop_list:\n",
    "        for image in paths:\n",
    "            copyfile(image, end_directory %(img_num,))\n",
    "            img_num +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting and sorting KDEF files into 4 emotions:\n",
    "\n",
    "#list for each emotion\n",
    "AN=0 #Angry\n",
    "HA=0 #Happy\n",
    "NE=0 #Neutral\n",
    "SA=0 #Sad\n",
    "\n",
    "\n",
    "participants = glob.glob(\"../datasets/KDEF/KDEF/*\")\n",
    "\n",
    "#get folder number\n",
    "for x in participants:\n",
    "    \n",
    "    #get folder number\n",
    "    part = \"%s\" %x[-4:] \n",
    "    \n",
    "    #for each folder\n",
    "    for file in glob.glob(\"../datasets/KDEF/KDEF/%s/*\" %part):\n",
    "        \n",
    "        #search using regex for emotion, HL, HR and S view\n",
    "        search_an = re.search('^.*\\S.\\d.AN[H|S].*', file)\n",
    "        \n",
    "        #if search is a success\n",
    "        if search_an is not None:\n",
    "            \n",
    "            #copy file into new directory with new file name\n",
    "            _ = copyfile(file, \"../datasets/KDEF/sorted_set/angry/%s.png\" %('AN'+ str(AN),))\n",
    "            AN+=1\n",
    "            \n",
    "        #if not, continue searching for other 3 emotions\n",
    "        else:\n",
    "            search_ha = re.search('^.*\\S.\\d.HA[H|S].*', file)\n",
    "            if search_ha is not None:\n",
    "                _ = copyfile(file, \"../datasets/KDEF/sorted_set/happy/%s.png\" %('HA'+ str(HA),))\n",
    "                HA+=1\n",
    "                \n",
    "            else:\n",
    "                search_ne= re.search('^.*\\S.\\d.NE[H|S].*', file)\n",
    "                if search_ne is not None:\n",
    "                    _ = copyfile(file, \"../datasets/KDEF/sorted_set/neutral/%s.png\" %('NE'+ str(NE),))\n",
    "                    NE+=1    \n",
    "                    \n",
    "                else:\n",
    "                    search_sa= re.search('^.*\\S.\\d.SA[H|S].*', file)\n",
    "                    if search_sa is not None:\n",
    "                        _ = copyfile(file, \"../datasets/KDEF/sorted_set/sad/%s.png\" %('SA'+ str(SA),))\n",
    "                        SA+=1  \n",
    "                        \n",
    "                    else:\n",
    "                        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:\n"
     ]
    }
   ],
   "source": [
    "# extracting and sorting CK+ files into 8 emotions:\n",
    "# pick out last 6 emotion frames and first 2 neutral frames from CK+ \n",
    "\n",
    "#Define emotion order\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] \n",
    "\n",
    "#Returns a list of all folders with participant numbers\n",
    "participants = glob.glob(\"source_emotion/*\") \n",
    "\n",
    "\n",
    "#store current participant number\n",
    "for x in participants:\n",
    "    part = \"%s\" %x[-4:] \n",
    "    \n",
    "    #Store list of sessions for current participant\n",
    "    for sessions in glob.glob(\"%s//*\" %x): \n",
    "        for files in glob.glob(\"%s//*\" %sessions):\n",
    "            current_session = files[20:-30]\n",
    "            file = open(files, 'r')\n",
    "            \n",
    "            #emotions are encoded as a float, readline as float, then convert to integer.\n",
    "            emotion = int(float(file.readline())) \n",
    "            \n",
    "            #get path for last 6 images in sequence, which contains the target emotion\n",
    "\n",
    "            sourcefile_emotion1 = sorted(glob.glob(\"source_images//%s//%s//*\" %(part, current_session)))[-1] \n",
    "            sourcefile_emotion2 = sorted(glob.glob(\"source_images//%s//%s//*\" %(part, current_session)))[-2] \n",
    "            sourcefile_emotion3 = sorted(glob.glob(\"source_images//%s//%s//*\" %(part, current_session)))[-3] \n",
    "            sourcefile_emotion4 = sorted(glob.glob(\"source_images//%s//%s//*\" %(part, current_session)))[-4]           \n",
    "            sourcefile_emotion5 = sorted(glob.glob(\"source_images//%s//%s//*\" %(part, current_session)))[-5] \n",
    "            sourcefile_emotion6 = sorted(glob.glob(\"source_images//%s//%s//*\" %(part, current_session)))[-6] \n",
    "\n",
    "            #get path for first 2 images in sequence, which contains the neutral emotion\n",
    "            sourcefile_neutral1 = sorted(glob.glob(\"source_images//%s//%s//*\" %(part, current_session)))[0] \n",
    "            sourcefile_neutral2 = sorted(glob.glob(\"source_images//%s//%s//*\" %(part, current_session)))[1] \n",
    "\n",
    "\n",
    "            #Generate path to put images\n",
    "            dest_emot1 = \"sorted_set//%s//%s\" %(emotions[emotion], sourcefile_emotion1[25:]) \n",
    "            dest_emot2 = \"sorted_set//%s//%s\" %(emotions[emotion], sourcefile_emotion2[25:]) \n",
    "            dest_emot3 = \"sorted_set//%s//%s\" %(emotions[emotion], sourcefile_emotion3[25:]) \n",
    "            dest_emot4 = \"sorted_set//%s//%s\" %(emotions[emotion], sourcefile_emotion4[25:]) \n",
    "            dest_emot5 = \"sorted_set//%s//%s\" %(emotions[emotion], sourcefile_emotion5[25:]) \n",
    "            dest_emot6 = \"sorted_set//%s//%s\" %(emotions[emotion], sourcefile_emotion6[25:]) \n",
    "            dest_neut1 = \"sorted_set//neutral//%s\" %sourcefile_neutral1[25:] \n",
    "            dest_neut2 = \"sorted_set//neutral//%s\" %sourcefile_neutral2[25:] \n",
    "            \n",
    "            #Copy files into desstination folders\n",
    "            copyfile(sourcefile_emotion1, dest_emot1) \n",
    "            copyfile(sourcefile_emotion2, dest_emot2) \n",
    "            copyfile(sourcefile_emotion3, dest_emot3) \n",
    "            copyfile(sourcefile_emotion4, dest_emot4) \n",
    "            copyfile(sourcefile_emotion5, dest_emot5) \n",
    "            copyfile(sourcefile_emotion6, dest_emot6) \n",
    "            copyfile(sourcefile_neutral1, dest_neut1) \n",
    "            copyfile(sourcefile_neutral2, dest_neut2) \n",
    "            \n",
    "            \n",
    "#move folders into datasets\n",
    "shutil.move(\"source_images\",\"../datasets/CK/\")\n",
    "shutil.move(\"source_emotion\",\"../datasets/CK/\")\n",
    "shutil.move(\"sorted_set\",\"../datasets/CK/\")\n",
    "print(\"(:\")\n",
    "\n",
    "#code credit: van Gent, P. (2016). Emotion Recognition With Python, OpenCV and a Face Dataset. \n",
    "#A tech blog about fun things with Python and embedded electronics. Retrieved from:\n",
    "#http://www.paulvangent.com/2016/04/01/emotion-recognition-with-python-opencv-and-a-face-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fer2013 combining training and validation set\n",
    "\n",
    "#validation folder source\n",
    "val_path_a = glob.glob(\"../datasets/fer2013/validation/angry/*\")\n",
    "val_path_h = glob.glob(\"../datasets/fer2013/validation/happy/*\")\n",
    "val_path_n = glob.glob(\"../datasets/fer2013/validation/neutral/*\")\n",
    "val_path_s = glob.glob(\"../datasets/fer2013/validation/sad/*\")\n",
    "\n",
    "#train folder source\n",
    "train_path_a = glob.glob(\"../datasets/fer2013/train/angry/*\")\n",
    "train_path_h = glob.glob(\"../datasets/fer2013/train/happy/*\")\n",
    "train_path_n = glob.glob(\"../datasets/fer2013/train/neutral/*\")\n",
    "train_path_s = glob.glob(\"../datasets/fer2013/train/sad/*\")\n",
    "\n",
    "\n",
    "# list of paths by destination\n",
    "a_list = [val_path_a, train_path_a]\n",
    "h_list = [val_path_h, train_path_h]\n",
    "n_list = [val_path_n, train_path_n]\n",
    "s_list = [val_path_s, train_path_s]\n",
    "\n",
    "#destination\n",
    "des_path_a = \"../datasets/fer2013/combined/angry/%s.png\"\n",
    "des_path_h = \"../datasets/fer2013/combined/happy/%s.png\"\n",
    "des_path_n = \"../datasets/fer2013/combined/neutral/%s.png\"\n",
    "des_path_s = \"../datasets/fer2013/combined/sad/%s.png\"\n",
    "\n",
    "\n",
    "#copy files to combined folder\n",
    "fer_to_combined(a_list, des_path_a)\n",
    "fer_to_combined(h_list, des_path_h)\n",
    "fer_to_combined(n_list, des_path_n)\n",
    "fer_to_combined(s_list, des_path_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combining all datasets into train folder\n",
    "\n",
    "# #CK+ paths\n",
    "# CK_path_a = glob.glob(\"../datasets/CK/sorted_set/anger/*\")\n",
    "# CK_path_h = glob.glob(\"../datasets/CK/sorted_set/happy/*\")\n",
    "# CK_path_n = glob.glob(\"../datasets/CK/sorted_set/neutral/*\")\n",
    "# CK_path_s = glob.glob(\"../datasets/CK/sorted_set/sadness/*\")\n",
    "\n",
    "# #fer2013 paths\n",
    "# fer2013_path_a = glob.glob(\"../datasets/fer2013/combined/angry/*\")\n",
    "# fer2013_path_h = glob.glob(\"../datasets/fer2013/combined/happy/*\")\n",
    "# fer2013_path_n = glob.glob(\"../datasets/fer2013/combined/neutral/*\")\n",
    "# fer2013_path_s = glob.glob(\"../datasets/fer2013/combined/sad/*\")\n",
    "\n",
    "# #KDEF paths\n",
    "# KDEF_path_a = glob.glob(\"../datasets/KDEF/sorted_set/angry/*\")\n",
    "# KDEF_path_h = glob.glob(\"../datasets/KDEF/sorted_set/happy/*\")\n",
    "# KDEF_path_n = glob.glob(\"../datasets/KDEF/sorted_set/neutral/*\")\n",
    "# KDEF_path_s = glob.glob(\"../datasets/KDEF/sorted_set/sad/*\")\n",
    "\n",
    "# #GENKI4K paths\n",
    "# g4_path_h = glob.glob(\"../datasets/genki4k/smile/*\")\n",
    "# g4_path_n = glob.glob(\"../datasets/genki4k/no_smile/*\")\n",
    "\n",
    "\n",
    "\n",
    "# # list of paths by destination\n",
    "# an_list = [CK_path_a, fer2013_path_a, KDEF_path_a]\n",
    "# ha_list = [CK_path_h, fer2013_path_h, KDEF_path_h, g4_path_h]\n",
    "# ne_list = [CK_path_n, fer2013_path_n, KDEF_path_n, g4_path_n]\n",
    "# sa_list = [CK_path_s, fer2013_path_s, KDEF_path_s]\n",
    "\n",
    "\n",
    "# #Destination\n",
    "# train_a = \"../datasets/train/angry/\"\n",
    "# train_h = \"../datasets/train/happy/\"\n",
    "# train_n = \"../datasets/train/neutral/\"\n",
    "# train_s = \"../datasets/train/sad/\"\n",
    "\n",
    "\n",
    "# #copy files into train folders\n",
    "\n",
    "# all_to_train(an_list, train_a)\n",
    "# all_to_train(ha_list, train_h)\n",
    "# all_to_train(ne_list, train_n)\n",
    "# all_to_train(sa_list, train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping faces and Greyscale - EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run\n",
    "\n",
    "# cropper = Cropper(width=48, height=48, face_percent=100)\n",
    "\n",
    "# def process_images(path_in, path_out):\n",
    "#     \"\"\"crops faces and converts them into greyscale\"\"\"\n",
    "#     img_num=10000\n",
    "#     for img in path_in:\n",
    "        \n",
    "        \n",
    "#         cropped_array = cropper.crop(img)\n",
    "#         if cropped_array is None:\n",
    "#             print(img)\n",
    "#             continue\n",
    "            \n",
    "#         cropped_image = Image.fromarray(cropped_array)\n",
    "#         bw_img = cropped_image.convert('L')\n",
    "#         bw_img.save(path_out %(img_num,))\n",
    "#         img_num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_a = glob.glob(\"../test_full/crop_test/angry/*\")\n",
    "# test_d = \"../test_full/crop_test/angry_done/%s.png\"\n",
    "\n",
    "# process_images(test_a, test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_a = glob.glob(\"../test_full/train/angry/*\")\n",
    "# train_h = glob.glob(\"../test_full/train/happy/*\")\n",
    "# train_n = glob.glob(\"../test_full/train/neutral/*\")\n",
    "# train_s = glob.glob(\"../test_full/train/sad/*\")\n",
    "# crop_train_a = \"../test_full/train_cropped/angry/%s.png\"\n",
    "# crop_train_h = \"../test_full/train_cropped/happy/%s.png\"\n",
    "# crop_train_n = \"../test_full/train_cropped/neutral/%s.png\"\n",
    "# crop_train_s = \"../test_full/train_cropped/sad/%s.png\"\n",
    "\n",
    "# # val_a = glob.glob(\"../test_full/validation/angry/*\")\n",
    "# # val_h = glob.glob(\"../test_full/validation/happy/*\")\n",
    "# # val_n = glob.glob(\"../test_full/validation/neutral/*\")\n",
    "# # val_s = glob.glob(\"../test_full/validation/sad/*\")\n",
    "# # crop_val_a = \"../test_full/validation_cropped/angry/%s.png\"\n",
    "# # crop_val_h = \"../test_full/validation_cropped/happy/%s.png\"\n",
    "# # crop_val_n = \"../test_full/validation_cropped/neutral/%s.png\"\n",
    "# # crop_val_s = \"../test_full/validation_cropped/sad/%s.png\"\n",
    "\n",
    "# process_images(train_a, crop_train_a)\n",
    "# process_images(train_h, crop_train_h)\n",
    "# process_images(train_n, crop_train_n)\n",
    "# process_images(train_s, crop_train_s)\n",
    "\n",
    "# # process_images(val_a, crop_val_a)\n",
    "# # process_images(val_h, crop_val_h)\n",
    "# # process_images(val_n, crop_val_n)\n",
    "# # process_images(val_s, crop_val_s)\n",
    "\n",
    "# ##validation has been cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_file = skimage.data.lbp_frontal_face_cascade_filename()\n",
    "# detector = Cascade(trained_file)\n",
    "# faceCascade = cv2.CascadeClassifier(\"../datasets/classifiers/haarcascade_frontalface_default.xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #not working\n",
    "# def process_images(path_in, path_out):\n",
    "#     for img in path_in:\n",
    "# #         img = Image.open(img)a\n",
    "#         img = cv2.imread(img)\n",
    "# #         bw_img = img.convert('L')\n",
    "# #         bw_img = color.rgb2gray(img)\n",
    "#         if img.ndim == 3:\n",
    "#             bw_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     #         bw_img = color.rgb2gray(img)\n",
    "#         else:\n",
    "#             bw_img = img \n",
    "\n",
    "#     #     detected = detector.detect_multi_scale(img= bw_img,\n",
    "#     #                                   scale_factor=1.2,\n",
    "#     #                                   step_ratio=1,\n",
    "#     #                                   min_size=(48,48),\n",
    "#     #                                   max_size=(500,500))\n",
    "\n",
    "#     #     detected = detector.detect_multi_scale(img= bw_img,\n",
    "#     #                                   scale_factor=1.2,\n",
    "#     #                                   step_ratio=1,\n",
    "#     #                                   min_size=(48,48),\n",
    "#     #                                   max_size=(500,500))\n",
    "\n",
    "#         detected = faceCascade.detectMultiScale(bw_img, 1.1, 5)\n",
    "#         img_num=0\n",
    "\n",
    "#         def get_face(d):\n",
    "#             # points in face rectangle\n",
    "#             x, y = d['r'], d['c']\n",
    "\n",
    "#             # width height\n",
    "#             width, height = d['r'] + d['width'], d['c'] + d['height']\n",
    "\n",
    "#             face=bw_img[x:width, y:height]\n",
    "#             return face\n",
    "\n",
    "#         for d in detected:\n",
    "#             face_img = get_face(d)\n",
    "#             face_done = cv2.resize(face_img, (48,48))\n",
    "#     #         face_done = face_img.resize((48,48))\n",
    "#             path_img_target = os.path.join(path_out, NAME_IMAGE_TARGET)\n",
    "#             io.imsave(path_img_target, face_done)\n",
    "#             face_done.save(\"../test_full/crop_test/angry_done/%s.png\" %(img_num,))\n",
    "#             img_num+=1\n",
    "\n",
    "#     print(f\"{path_in} processed into {path_out}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #same as cropper\n",
    "# def process_images(path_in, path_out):\n",
    "#     img_num=0\n",
    "    \n",
    "#     faceCascade = cv2.CascadeClassifier(\"../datasets/classifiers/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    \n",
    "#     for img in path_in:\n",
    "#         img = cv2.imread(img)\n",
    "#         if img.ndim == 3:\n",
    "#             bw_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         else:\n",
    "#             bw_img = img \n",
    "            \n",
    "#         faces = faceCascade.detectMultiScale(bw_img, scaleFactor=1.1, minSize=(48, 48))\n",
    "        \n",
    "#         for (x, y, w, h) in faces:\n",
    "#             cv2.rectangle(bw_img, (x, y), (x + w, y + h), (0, 255, 0), 0)\n",
    "#             roi_bw = bw_img[y:y + h, x:x + w]\n",
    "# #             print(\"[INFO] Object found. Saving locally.\")\n",
    "# #             cv2.imwrite(str(w) + str(h) + '_faces.jpg', roi_color)\n",
    "#             face_done = cv2.resize(roi_bw, (48,48))\n",
    "        \n",
    "#             cv2.imwrite(\"../test_full/crop_test/angry_done/%s.png\" %(img_num,), face_done)\n",
    "        \n",
    "#         img_num+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
