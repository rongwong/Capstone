{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# code credits: Durgesh Thakur\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../non_load/fer2013/train'\n",
    "validation_data_dir = '../non_load/fer2013/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "img_rows,img_cols = 48,48\n",
    "batch_size = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=30,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   width_shift_range=0.4,\n",
    "                                   height_shift_range=0.4,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28643 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    target_size=(img_rows,img_cols),\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                              color_mode='grayscale',\n",
    "                                                              target_size=(img_rows,img_cols),\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,167\n",
      "Trainable params: 1,325,991\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# layers\n",
    "model = Sequential()\n",
    "\n",
    "# Block-1\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-2 \n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-3\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-4 \n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block-5\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block-6\n",
    "\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block-7\n",
    "\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "checkpoint = ModelCheckpoint('rong_test1_fer.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=9,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks = [earlystop,checkpoint,reduce_lr]\n",
    "# callbacks = [checkpoint,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-e7adca1b7e5a>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 2.6468 - accuracy: 0.1749\n",
      "Epoch 00001: val_loss improved from inf to 1.91399, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 43s 179ms/step - loss: 2.6468 - accuracy: 0.1749 - val_loss: 1.9140 - val_accuracy: 0.2227 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 2.1293 - accuracy: 0.1959\n",
      "Epoch 00002: val_loss improved from 1.91399 to 1.82215, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 52s 218ms/step - loss: 2.1293 - accuracy: 0.1959 - val_loss: 1.8221 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.9791 - accuracy: 0.2079\n",
      "Epoch 00003: val_loss improved from 1.82215 to 1.81791, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 61s 255ms/step - loss: 1.9791 - accuracy: 0.2079 - val_loss: 1.8179 - val_accuracy: 0.2514 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.8927 - accuracy: 0.2171\n",
      "Epoch 00004: val_loss improved from 1.81791 to 1.78253, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 62s 260ms/step - loss: 1.8927 - accuracy: 0.2171 - val_loss: 1.7825 - val_accuracy: 0.2566 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.8403 - accuracy: 0.2337\n",
      "Epoch 00005: val_loss improved from 1.78253 to 1.78227, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 61s 255ms/step - loss: 1.8403 - accuracy: 0.2337 - val_loss: 1.7823 - val_accuracy: 0.2575 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.8190 - accuracy: 0.2483\n",
      "Epoch 00006: val_loss did not improve from 1.78227\n",
      "238/238 [==============================] - 61s 256ms/step - loss: 1.8190 - accuracy: 0.2483 - val_loss: 1.7961 - val_accuracy: 0.2454 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.8014 - accuracy: 0.2562\n",
      "Epoch 00007: val_loss improved from 1.78227 to 1.77842, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 62s 259ms/step - loss: 1.8014 - accuracy: 0.2562 - val_loss: 1.7784 - val_accuracy: 0.2635 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7963 - accuracy: 0.2524\n",
      "Epoch 00008: val_loss improved from 1.77842 to 1.77201, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 53s 224ms/step - loss: 1.7963 - accuracy: 0.2524 - val_loss: 1.7720 - val_accuracy: 0.2626 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.8000 - accuracy: 0.2449\n",
      "Epoch 00009: val_loss did not improve from 1.77201\n",
      "238/238 [==============================] - 67s 281ms/step - loss: 1.8000 - accuracy: 0.2449 - val_loss: 1.7808 - val_accuracy: 0.2560 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7869 - accuracy: 0.2623\n",
      "Epoch 00010: val_loss did not improve from 1.77201\n",
      "238/238 [==============================] - 57s 239ms/step - loss: 1.7869 - accuracy: 0.2623 - val_loss: 1.7728 - val_accuracy: 0.2621 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7849 - accuracy: 0.2591\n",
      "Epoch 00011: val_loss improved from 1.77201 to 1.75695, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 47s 198ms/step - loss: 1.7849 - accuracy: 0.2591 - val_loss: 1.7570 - val_accuracy: 0.2830 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7813 - accuracy: 0.2622\n",
      "Epoch 00012: val_loss did not improve from 1.75695\n",
      "238/238 [==============================] - 54s 228ms/step - loss: 1.7813 - accuracy: 0.2622 - val_loss: 1.7680 - val_accuracy: 0.2739 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7727 - accuracy: 0.2676\n",
      "Epoch 00013: val_loss improved from 1.75695 to 1.75598, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 51s 214ms/step - loss: 1.7727 - accuracy: 0.2676 - val_loss: 1.7560 - val_accuracy: 0.2799 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7760 - accuracy: 0.2629\n",
      "Epoch 00014: val_loss improved from 1.75598 to 1.73765, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 48s 201ms/step - loss: 1.7760 - accuracy: 0.2629 - val_loss: 1.7376 - val_accuracy: 0.2905 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7624 - accuracy: 0.2686\n",
      "Epoch 00015: val_loss improved from 1.73765 to 1.71728, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 47s 196ms/step - loss: 1.7624 - accuracy: 0.2686 - val_loss: 1.7173 - val_accuracy: 0.2966 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7456 - accuracy: 0.2907\n",
      "Epoch 00016: val_loss improved from 1.71728 to 1.69708, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 47s 198ms/step - loss: 1.7456 - accuracy: 0.2907 - val_loss: 1.6971 - val_accuracy: 0.3052 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7222 - accuracy: 0.2912\n",
      "Epoch 00017: val_loss did not improve from 1.69708\n",
      "238/238 [==============================] - 48s 201ms/step - loss: 1.7222 - accuracy: 0.2912 - val_loss: 1.7240 - val_accuracy: 0.3124 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.7158 - accuracy: 0.2952\n",
      "Epoch 00018: val_loss did not improve from 1.69708\n",
      "238/238 [==============================] - 55s 230ms/step - loss: 1.7158 - accuracy: 0.2952 - val_loss: 1.6977 - val_accuracy: 0.3356 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.6911 - accuracy: 0.3145\n",
      "Epoch 00019: val_loss improved from 1.69708 to 1.66127, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 86s 362ms/step - loss: 1.6911 - accuracy: 0.3145 - val_loss: 1.6613 - val_accuracy: 0.3520 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.6792 - accuracy: 0.3185\n",
      "Epoch 00020: val_loss did not improve from 1.66127\n",
      "238/238 [==============================] - 98s 410ms/step - loss: 1.6792 - accuracy: 0.3185 - val_loss: 1.7048 - val_accuracy: 0.3440 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.6544 - accuracy: 0.3412\n",
      "Epoch 00021: val_loss did not improve from 1.66127\n",
      "238/238 [==============================] - 109s 460ms/step - loss: 1.6544 - accuracy: 0.3412 - val_loss: 1.7123 - val_accuracy: 0.3552 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.6323 - accuracy: 0.3452\n",
      "Epoch 00022: val_loss did not improve from 1.66127\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "238/238 [==============================] - 106s 447ms/step - loss: 1.6323 - accuracy: 0.3452 - val_loss: 1.7383 - val_accuracy: 0.3879 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5886 - accuracy: 0.3724\n",
      "Epoch 00023: val_loss improved from 1.66127 to 1.62471, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 82s 346ms/step - loss: 1.5886 - accuracy: 0.3724 - val_loss: 1.6247 - val_accuracy: 0.4129 - lr: 2.0000e-04\n",
      "Epoch 24/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5805 - accuracy: 0.3851\n",
      "Epoch 00024: val_loss improved from 1.62471 to 1.57941, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 82s 346ms/step - loss: 1.5805 - accuracy: 0.3851 - val_loss: 1.5794 - val_accuracy: 0.4224 - lr: 2.0000e-04\n",
      "Epoch 25/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5667 - accuracy: 0.3848\n",
      "Epoch 00025: val_loss did not improve from 1.57941\n",
      "238/238 [==============================] - 78s 327ms/step - loss: 1.5667 - accuracy: 0.3848 - val_loss: 1.5943 - val_accuracy: 0.4241 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5341 - accuracy: 0.3978\n",
      "Epoch 00026: val_loss improved from 1.57941 to 1.56692, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 89s 375ms/step - loss: 1.5341 - accuracy: 0.3978 - val_loss: 1.5669 - val_accuracy: 0.4236 - lr: 2.0000e-04\n",
      "Epoch 27/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5297 - accuracy: 0.4024\n",
      "Epoch 00027: val_loss did not improve from 1.56692\n",
      "238/238 [==============================] - 85s 358ms/step - loss: 1.5297 - accuracy: 0.4024 - val_loss: 1.5690 - val_accuracy: 0.4353 - lr: 2.0000e-04\n",
      "Epoch 28/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5213 - accuracy: 0.4099\n",
      "Epoch 00028: val_loss improved from 1.56692 to 1.54620, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 82s 343ms/step - loss: 1.5213 - accuracy: 0.4099 - val_loss: 1.5462 - val_accuracy: 0.4184 - lr: 2.0000e-04\n",
      "Epoch 29/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5385 - accuracy: 0.4018\n",
      "Epoch 00029: val_loss did not improve from 1.54620\n",
      "238/238 [==============================] - 86s 363ms/step - loss: 1.5385 - accuracy: 0.4018 - val_loss: 1.5602 - val_accuracy: 0.4351 - lr: 2.0000e-04\n",
      "Epoch 30/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5069 - accuracy: 0.4143\n",
      "Epoch 00030: val_loss did not improve from 1.54620\n",
      "238/238 [==============================] - 91s 383ms/step - loss: 1.5069 - accuracy: 0.4143 - val_loss: 1.5506 - val_accuracy: 0.4351 - lr: 2.0000e-04\n",
      "Epoch 31/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.5072 - accuracy: 0.4174\n",
      "Epoch 00031: val_loss improved from 1.54620 to 1.53048, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 82s 347ms/step - loss: 1.5072 - accuracy: 0.4174 - val_loss: 1.5305 - val_accuracy: 0.4282 - lr: 2.0000e-04\n",
      "Epoch 32/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4842 - accuracy: 0.4190\n",
      "Epoch 00032: val_loss improved from 1.53048 to 1.51710, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 85s 359ms/step - loss: 1.4842 - accuracy: 0.4190 - val_loss: 1.5171 - val_accuracy: 0.4322 - lr: 2.0000e-04\n",
      "Epoch 33/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4921 - accuracy: 0.4196\n",
      "Epoch 00033: val_loss did not improve from 1.51710\n",
      "238/238 [==============================] - 87s 367ms/step - loss: 1.4921 - accuracy: 0.4196 - val_loss: 1.5648 - val_accuracy: 0.4302 - lr: 2.0000e-04\n",
      "Epoch 34/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4740 - accuracy: 0.4258\n",
      "Epoch 00034: val_loss did not improve from 1.51710\n",
      "238/238 [==============================] - 87s 365ms/step - loss: 1.4740 - accuracy: 0.4258 - val_loss: 1.5612 - val_accuracy: 0.4448 - lr: 2.0000e-04\n",
      "Epoch 35/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4902 - accuracy: 0.4221\n",
      "Epoch 00035: val_loss improved from 1.51710 to 1.49526, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 84s 354ms/step - loss: 1.4902 - accuracy: 0.4221 - val_loss: 1.4953 - val_accuracy: 0.4454 - lr: 2.0000e-04\n",
      "Epoch 36/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4675 - accuracy: 0.4341\n",
      "Epoch 00036: val_loss did not improve from 1.49526\n",
      "238/238 [==============================] - 85s 358ms/step - loss: 1.4675 - accuracy: 0.4341 - val_loss: 1.5247 - val_accuracy: 0.4394 - lr: 2.0000e-04\n",
      "Epoch 37/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4594 - accuracy: 0.4391\n",
      "Epoch 00037: val_loss did not improve from 1.49526\n",
      "238/238 [==============================] - 86s 363ms/step - loss: 1.4594 - accuracy: 0.4391 - val_loss: 1.5197 - val_accuracy: 0.4445 - lr: 2.0000e-04\n",
      "Epoch 38/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4682 - accuracy: 0.4350\n",
      "Epoch 00038: val_loss did not improve from 1.49526\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "238/238 [==============================] - 85s 357ms/step - loss: 1.4682 - accuracy: 0.4350 - val_loss: 1.5148 - val_accuracy: 0.4440 - lr: 2.0000e-04\n",
      "Epoch 39/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4423 - accuracy: 0.4420\n",
      "Epoch 00039: val_loss improved from 1.49526 to 1.48662, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 84s 353ms/step - loss: 1.4423 - accuracy: 0.4420 - val_loss: 1.4866 - val_accuracy: 0.4491 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4505 - accuracy: 0.4391\n",
      "Epoch 00040: val_loss improved from 1.48662 to 1.47669, saving model to rong_test1_fer.h5\n",
      "238/238 [==============================] - 84s 354ms/step - loss: 1.4505 - accuracy: 0.4391 - val_loss: 1.4767 - val_accuracy: 0.4529 - lr: 4.0000e-05\n",
      "Epoch 41/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4469 - accuracy: 0.4466\n",
      "Epoch 00041: val_loss did not improve from 1.47669\n",
      "238/238 [==============================] - 85s 356ms/step - loss: 1.4469 - accuracy: 0.4466 - val_loss: 1.4860 - val_accuracy: 0.4503 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4304 - accuracy: 0.4529\n",
      "Epoch 00042: val_loss did not improve from 1.47669\n",
      "238/238 [==============================] - 86s 361ms/step - loss: 1.4304 - accuracy: 0.4529 - val_loss: 1.4775 - val_accuracy: 0.4511 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4346 - accuracy: 0.4500\n",
      "Epoch 00043: val_loss did not improve from 1.47669\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "238/238 [==============================] - 85s 358ms/step - loss: 1.4346 - accuracy: 0.4500 - val_loss: 1.4783 - val_accuracy: 0.4549 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4345 - accuracy: 0.4483\n",
      "Epoch 00044: val_loss did not improve from 1.47669\n",
      "238/238 [==============================] - 84s 351ms/step - loss: 1.4345 - accuracy: 0.4483 - val_loss: 1.4979 - val_accuracy: 0.4511 - lr: 8.0000e-06\n",
      "Epoch 45/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4415 - accuracy: 0.4418\n",
      "Epoch 00045: val_loss did not improve from 1.47669\n",
      "238/238 [==============================] - 85s 356ms/step - loss: 1.4415 - accuracy: 0.4418 - val_loss: 1.4900 - val_accuracy: 0.4511 - lr: 8.0000e-06\n",
      "Epoch 46/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4219 - accuracy: 0.4540\n",
      "Epoch 00046: val_loss did not improve from 1.47669\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "238/238 [==============================] - 85s 359ms/step - loss: 1.4219 - accuracy: 0.4540 - val_loss: 1.4825 - val_accuracy: 0.4540 - lr: 8.0000e-06\n",
      "Epoch 47/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4247 - accuracy: 0.4530\n",
      "Epoch 00047: val_loss did not improve from 1.47669\n",
      "238/238 [==============================] - 89s 375ms/step - loss: 1.4247 - accuracy: 0.4530 - val_loss: 1.4771 - val_accuracy: 0.4540 - lr: 1.6000e-06\n",
      "Epoch 48/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4271 - accuracy: 0.4526\n",
      "Epoch 00048: val_loss did not improve from 1.47669\n",
      "238/238 [==============================] - 88s 369ms/step - loss: 1.4271 - accuracy: 0.4526 - val_loss: 1.4887 - val_accuracy: 0.4511 - lr: 1.6000e-06\n",
      "Epoch 49/100\n",
      "238/238 [==============================] - ETA: 0s - loss: 1.4300 - accuracy: 0.4585Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.47669\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "238/238 [==============================] - 83s 348ms/step - loss: 1.4300 - accuracy: 0.4585 - val_loss: 1.4825 - val_accuracy: 0.4483 - lr: 1.6000e-06\n",
      "Epoch 00049: early stopping\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = 28643\n",
    "nb_validation_samples = 3589\n",
    "epochs=100\n",
    "\n",
    "history=model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(train_loss, label = 'Train Loss', color = 'gold')\n",
    "plt.plot(test_loss, label = 'Test Loss', color = 'orange')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('../datasets/classifiers/haarcascade_frontalface_default.xml')\n",
    "classifier =load_model('rong_test1_fer.h5')\n",
    "\n",
    "# class_labels = ['angry','disgust','happy','neutral','sad']\n",
    "class_labels = ['angry','disgust','fear','happy','neutral','sad', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0),np.zeros((48,48),np.uint8),img\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "\n",
    "    try:\n",
    "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (x,w,y,h),np.zeros((48,48),np.uint8),img\n",
    "    return (x,w,y,h),roi_gray,img\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = cap.read()\n",
    "    labels = []\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "    # rect,face,image = face_detector(frame)\n",
    "\n",
    "\n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi = roi_gray.astype('float')/255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "        # make a prediction on the ROI, then lookup the class\n",
    "\n",
    "            preds = classifier.predict(roi)[0]\n",
    "            label=class_labels[(preds.argmax())]\n",
    "            label_position = (x,y)\n",
    "            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "        else:\n",
    "            cv2.putText(frame,'No Face Found',(20,60),cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "    cv2.imshow('Emotion Detector',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
